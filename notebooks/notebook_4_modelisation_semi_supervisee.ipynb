{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "302a339f",
   "metadata": {},
   "source": [
    "# Mission - Analysez des images médicales avec des méthodes semi-supervisées\n",
    "\n",
    "Vous êtes Data Scientist junior spécialisé en Computer Vision au sein de CurelyticsIA, une startup innovante dans le domaine de la e-santé. L’entreprise développe des solutions basées sur l’intelligence artificielle pour assister les professionnels de santé dans l’analyse d’images médicales, en particulier des IRM.\n",
    " \n",
    "Dans le cadre d’un nouveau projet R&D, CurelyticsIA souhaite explorer la possibilité d’automatiser la détection de tumeurs du cerveau. Un ensemble conséquent de radios a été collecté : la majorité de ces images ne dispose d’aucun étiquetage, tandis qu’un sous-ensemble limité a été annoté par des radiologues experts.\n",
    " \n",
    "Vous êtes chargé de concevoir une première exploration analytique du jeu de données. Plus précisément, votre mission est de :\n",
    "- Explorer les images et extraire des caractéristiques visuelles via un modèle pré-entraîné ;\n",
    "- Appliquer des méthodes de clustering pour identifier des structures ou regroupements dans les données ;\n",
    "- Mettre en œuvre une méthode d’apprentissage semi-supervisé à partir des quelques étiquettes disponibles ;\n",
    "- Synthétiser vos résultats, formuler des recommandations, et les présenter à votre équipe projet.\n",
    "\n",
    "**Mail à prendre en compte :**\n",
    "\n",
    "Comme discuté lors de notre dernière réunion, tu es assigné à la première phase du projet BrainScanAI. Tu trouveras en pièce jointe un fichier zip contenant :\n",
    "- Le jeu de données de radiographies (en format PNG + métadonnées anonymisées),\n",
    "- Une documentation technique sur le format des images ;\n",
    "- Une liste restreinte de labels annotés par nos partenaires hospitaliers (normal/cancéreux). \n",
    "\n",
    "Pour info, notre budget actuel pour la labellisation par IA est de 300 euros pour ce dataset. \n",
    "\n",
    "Tes objectifs :\n",
    "1) Extraire des caractéristiques visuelles pertinentes à l’aide d’un modèle pré-entraîné (type ResNet ou équivalent).\n",
    "2) Réaliser un clustering exploratoire pour identifier des regroupements naturels.\n",
    "3) Mettre en œuvre une méthode semi-supervisée en exploitant les labels partiels pour prédire les étiquettes manquantes.\n",
    "4) Proposer des livrables au format Notebook contenant :\n",
    "    - l’extraction des features\n",
    "    - le preprocessing adapté au(x) modèle(s) utilisés\n",
    "    - l’analyse non-supervisée (.ipynb)\n",
    "    - l’entraînement de modèles de clustering\n",
    "    - l’approche semi-supervisée (.ipynb)\n",
    " \n",
    "Ces livrables doivent être accompagnés d’un support de présentation proposant des recommandations techniques pour un passage à l’échelle (budget de 5 000 euros pour 4 millions d’images à labelliser). Est-ce que ce passage te paraît faisable et si oui, sous quelles conditions ?\n",
    "\n",
    "5) Rédiger une synthèse de ton approche et de tes résultats dans un support de présentation. Les contraintes :\n",
    "    - Travailler en Python.\n",
    "    - Tester plusieurs algorithmes.\n",
    "    - Avoir des métriques pertinentes en fonction de l’erreur la plus importante (F1, Acc, Précision, ou autre ?).\n",
    "    - Clairement définir ce que tu considères comme un objectif atteint (“definition of done”).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43cfcb",
   "metadata": {},
   "source": [
    "## Étape 4 - Appliquez une méthode semi supervisée\n",
    "\n",
    "Entraîner un modèle de type CNN sur votre jeu de données “faiblement” labellisé dans un premier temps puis et évaluer ses performances. Poursuivez ensuite l’entraînement de ce même modèle sur le jeu de données “fortement” labellisé. Comparer ensuite la différence de performance entre entraînement supervisé (modèle entraîné sur le jeu de données “fortement” labellisé uniquement) et semi-supervisé (entraîné sur les 2 jeux de données).\n",
    " \n",
    "**Prérequis**\n",
    "- Avoir préparé un ensemble labellisé et un ensemble non labellisé\n",
    "\n",
    "**Résultat attendu**\n",
    "- Modèle entraîné et validé avec les métriques choisies (accuracy, F1-score ou autre ?)\n",
    "\n",
    "**Recommandations**\n",
    "- Réaliser un split train/test équilibré\n",
    "- Pour chaque évaluation des performances: attention à ce que le jeu de test soir bien des données jamais vues par le modèle évalué lors de son entraînement.\n",
    "- Utiliser des visualisations bien lisibles pour analyser les performances.\n",
    "\n",
    "**Outils**\n",
    "- Torchvision / TenforFlow / Transformers / Numpy / Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541efc2",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "153c4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies de base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librairies spécifiques\n",
    "import os # permet de travailler avec le système de fichiers\n",
    "from PIL import Image # ouvrir et manipuler des images\n",
    "import glob\n",
    "\n",
    "# Librairies PyTorch\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms # pour effectuer les changements de format, entre autres\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Librairies Scikit-learn\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "# Choisit automatiquement GPU si disponible, sinon CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e4386",
   "metadata": {},
   "source": [
    "### Enregistrement des dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb8b5a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des images labellisées...\n",
      "Images labellisées chargées : torch.Size([100, 3, 224, 224])\n",
      "Chargement des images pseudo-labellisées...\n",
      "Images pseudo-labellisées chargées : torch.Size([1406, 3, 224, 224])\n",
      "\n",
      " Découpage terminé.\n",
      "Train supervisé : torch.Size([80, 3, 224, 224])\n",
      "Test  supervisé : torch.Size([20, 3, 224, 224])\n",
      "\n",
      " RÉSUMÉ DES TENSEURS DISPONIBLES :\n",
      " X_train_labeled  : torch.Size([80, 3, 224, 224])\n",
      " y_train_labeled  : torch.Size([80])\n",
      " X_test_labeled   : torch.Size([20, 3, 224, 224])\n",
      " y_test_labeled   : torch.Size([20])\n",
      "----------------------------------------\n",
      " X_unlabeled      : torch.Size([1406, 3, 224, 224])\n",
      " pseudo_labels    : torch.Size([1406])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chargement des chemins vers les images labellisées\n",
    "\n",
    "cancer_paths = glob.glob(\"../mri_dataset_brain_cancer_oc/avec_labels/cancer/*\")\n",
    "normal_paths = glob.glob(\"../mri_dataset_brain_cancer_oc/avec_labels/normal/*\")\n",
    "\n",
    "# On regroupe les chemins\n",
    "paths_labeled = cancer_paths + normal_paths\n",
    "\n",
    "# Création des labels : 1 = cancer, 0 = normal\n",
    "y_labeled = [1] * len(cancer_paths) + [0] * len(normal_paths)\n",
    "\n",
    "\n",
    "# Chargement des pseudo-labels\n",
    "\n",
    "pseudo_df = pd.read_csv(\"../data/processed/pseudo_labels.csv\")\n",
    "\n",
    "# On récupère les chemins des images non labellisées dans le même ordre\n",
    "unlabeled_paths = sorted(glob.glob(\"../mri_dataset_brain_cancer_oc/sans_label/*\"))\n",
    "\n",
    "# Vérification de cohérence\n",
    "assert len(unlabeled_paths) == len(pseudo_df), \\\n",
    "       \"Erreur : nb d'images ≠ nb de pseudo-labels\"\n",
    "\n",
    "pseudo_labels = pseudo_df[\"pseudo_label\"].values.tolist()\n",
    "\n",
    "# Transformations à appliquer aux images\n",
    "\n",
    "# Resize → Tensor → normalisation 0-1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Chargement effectif des images labellisées\n",
    "\n",
    "print(\"Chargement des images labellisées...\")\n",
    "\n",
    "X_labeled = torch.stack([\n",
    "    transform(Image.open(path).convert(\"RGB\"))\n",
    "    for path in paths_labeled\n",
    "])\n",
    "\n",
    "y_labeled = torch.tensor(y_labeled)\n",
    "\n",
    "print(f\"Images labellisées chargées : {X_labeled.shape}\")\n",
    "\n",
    "\n",
    "# Chargement des images avec pseudo-labels\n",
    "\n",
    "print(\"Chargement des images pseudo-labellisées...\")\n",
    "\n",
    "X_unlabeled = torch.stack([\n",
    "    transform(Image.open(path).convert(\"RGB\"))\n",
    "    for path in unlabeled_paths\n",
    "])\n",
    "\n",
    "pseudo_labels = torch.tensor(pseudo_labels)\n",
    "\n",
    "print(f\"Images pseudo-labellisées chargées : {X_unlabeled.shape}\")\n",
    "\n",
    "\n",
    "# Train/test split sur le dataset supervisé uniquement\n",
    "\n",
    "X_train_labeled, X_test_labeled, y_train_labeled, y_test_labeled = train_test_split(\n",
    "    X_labeled,\n",
    "    y_labeled,\n",
    "    test_size=0.2,\n",
    "    stratify=y_labeled,   # conserve le même ratio cancer/normal\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n Découpage terminé.\")\n",
    "print(f\"Train supervisé : {X_train_labeled.shape}\")\n",
    "print(f\"Test  supervisé : {X_test_labeled.shape}\")\n",
    "\n",
    "\n",
    "# 7) Résumé global\n",
    "\n",
    "print(\"\\n RÉSUMÉ DES TENSEURS DISPONIBLES :\")\n",
    "print(f\" X_train_labeled  : {X_train_labeled.shape}\")\n",
    "print(f\" y_train_labeled  : {y_train_labeled.shape}\")\n",
    "print(f\" X_test_labeled   : {X_test_labeled.shape}\")\n",
    "print(f\" y_test_labeled   : {y_test_labeled.shape}\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\" X_unlabeled      : {X_unlabeled.shape}\")\n",
    "print(f\" pseudo_labels    : {pseudo_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f756713",
   "metadata": {},
   "source": [
    "## Création de notre modèle CNN simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0599df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # Première couche de convolution : 3 canaux RGB -> 32 / détecte bords, intensités\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Pooling pour réduire la taille de l'image\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # Deuxième convolution : 32 -> 64 / détecte formes plus larges\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Troisième convolution : 64 -> 128 / détecte motifs médicaux\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Couche fully connected : calculée pour image 224*224 -> 28x28 après 3 poolings\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 256)\n",
    "\n",
    "        # Dropout pour réduire l'overfitting (important sur un petit dataset)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Dernière couche : 256 -> 1 (classification binaire)\n",
    "        self.fc2 = nn.Linear(256,1)\n",
    "\n",
    "        # La fonction qui définit comment le modèle traite une image.\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Bloc 1 : conv -> relu -> pool\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "        # Bloc 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Bloc 3\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Aplatit le tenseur pour la couche fully connected\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Dense layer + dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Sortie sigmoïde pour une probabilité entre 0 et 1\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad8797",
   "metadata": {},
   "source": [
    "#### Création des dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8359a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size pour entraîner par petits lots\n",
    "batch_size = 32\n",
    "\n",
    "# Dataset supervisé (vrais labels) ENTIEREMENT basé sur les données d'entraînement\n",
    "dataset_sup = TensorDataset(X_train_labeled, y_train_labeled)\n",
    "\n",
    "# Dataset pseudo-labellisé — ne change pas car X_unlabeled ne fait pas partie du split\n",
    "dataset_pseudo = TensorDataset(X_unlabeled, pseudo_labels)\n",
    "\n",
    "# Dataset fine-tuning (mêmes vraies données que supervisé → X_train)\n",
    "dataset_ft = TensorDataset(X_train_labeled, y_train_labeled)\n",
    "\n",
    "# Dataset test (utilise le split test)\n",
    "dataset_test = TensorDataset(X_test_labeled, y_test_labeled)\n",
    "\n",
    "# DataLoaders (chargent les données par batch)\n",
    "loader_sup = DataLoader(TensorDataset(X_train_labeled, y_train_labeled),\n",
    "                        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loader_test = DataLoader(TensorDataset(X_test_labeled, y_test_labeled),\n",
    "                         batch_size=batch_size, shuffle=False)\n",
    "\n",
    "loader_pseudo = DataLoader(TensorDataset(X_unlabeled, pseudo_labels),\n",
    "                           batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loader_ft = DataLoader(TensorDataset(X_train_labeled, y_train_labeled),\n",
    "                       batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf90a22",
   "metadata": {},
   "source": [
    "#### Entraînement supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62ae30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised(model, loader, epochs=10, lr=1e-4):\n",
    "    \n",
    "    # Envoie le modèle sur GPU/CPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Perte pour binaire\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Optimiseur Adam\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()  # Mode entraînement\n",
    "        total_loss = 0\n",
    "\n",
    "        # On parcourt les batches\n",
    "        for X, y in loader:\n",
    "\n",
    "            X = X.to(device)                       # Images sur GPU/CPU\n",
    "            y = y.float().to(device).view(-1, 1)   # Labels → float + reshape\n",
    "\n",
    "            optimizer.zero_grad()                  # Reset gradients\n",
    "            pred = model(X)                        # Prédiction du CNN\n",
    "            loss = criterion(pred, y)              # Calcul perte\n",
    "            loss.backward()                        # Backpropagation\n",
    "            optimizer.step()                       # Mise à jour des poids\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Sauvegarde moyenne des pertes\n",
    "        losses.append(total_loss / len(loader))\n",
    "        print(f\"[SUP] Epoch {epoch+1}/{epochs} - Loss: {losses[-1]:.4f}\")\n",
    "\n",
    "    return model, losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296219b",
   "metadata": {},
   "source": [
    "#### Pré-entraînement sur pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "464cec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_pseudo(model, loader, epochs=10, lr=1e-4):\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X, y in loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.float().to(device).view(-1, 1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"[PSEUDO] Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05525b",
   "metadata": {},
   "source": [
    "#### Fine-tuning sur vrais labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87e167fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model, loader, epochs=5, lr=5e-5):\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            y = y.float().to(device).view(-1,1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"[FINETUNE] Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1fffb4",
   "metadata": {},
   "source": [
    "#### Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de958c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    truths = []\n",
    "\n",
    "    with torch.no_grad():  # Pas de gradient en test\n",
    "        for X, y in loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            pred = model(X).cpu().numpy()     # Sortie du modèle\n",
    "            pred = (pred > 0.5).astype(int)   # Prob → classe (0/1)\n",
    "\n",
    "            preds.extend(pred.flatten().tolist())\n",
    "            truths.extend(y.numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(truths, preds)\n",
    "    f1 = f1_score(truths, preds)\n",
    "    rec = recall_score(truths, preds)\n",
    "\n",
    "    return acc, f1, rec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fecd59",
   "metadata": {},
   "source": [
    "#### Supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d804ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUP] Epoch 1/10 - Loss: 0.7099\n",
      "[SUP] Epoch 2/10 - Loss: 0.6686\n",
      "[SUP] Epoch 3/10 - Loss: 0.6340\n",
      "[SUP] Epoch 4/10 - Loss: 0.5858\n",
      "[SUP] Epoch 5/10 - Loss: 0.5492\n",
      "[SUP] Epoch 6/10 - Loss: 0.5098\n",
      "[SUP] Epoch 7/10 - Loss: 0.4674\n",
      "[SUP] Epoch 8/10 - Loss: 0.4489\n",
      "[SUP] Epoch 9/10 - Loss: 0.4189\n",
      "[SUP] Epoch 10/10 - Loss: 0.4221\n"
     ]
    }
   ],
   "source": [
    "model_sup = SimpleCNN()\n",
    "model_sup, losses_sup = train_supervised(model_sup, loader_sup)\n",
    "acc_sup, f1_sup, rec_sup = evaluate(model_sup, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f171d535",
   "metadata": {},
   "source": [
    "#### Semi-supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9937ca0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PSEUDO] Epoch 1/10\n",
      "[PSEUDO] Epoch 2/10\n",
      "[PSEUDO] Epoch 3/10\n",
      "[PSEUDO] Epoch 4/10\n",
      "[PSEUDO] Epoch 5/10\n",
      "[PSEUDO] Epoch 6/10\n",
      "[PSEUDO] Epoch 7/10\n",
      "[PSEUDO] Epoch 8/10\n",
      "[PSEUDO] Epoch 9/10\n",
      "[PSEUDO] Epoch 10/10\n",
      "[FINETUNE] Epoch 1/5\n",
      "[FINETUNE] Epoch 2/5\n",
      "[FINETUNE] Epoch 3/5\n",
      "[FINETUNE] Epoch 4/5\n",
      "[FINETUNE] Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "model_semi = SimpleCNN()\n",
    "model_semi = pretrain_pseudo(model_semi, loader_pseudo)\n",
    "model_semi = finetune(model_semi, loader_ft)\n",
    "acc_semi, f1_semi, rec_semi = evaluate(model_semi, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3c0c8",
   "metadata": {},
   "source": [
    "#### Tableau final comparatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c362dcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Méthode</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supervisé</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semi-supervisé</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Méthode  Accuracy        F1  Recall\n",
       "0       Supervisé      0.85  0.842105     0.8\n",
       "1  Semi-supervisé      0.80  0.777778     0.7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    \"Méthode\": [\"Supervisé\", \"Semi-supervisé\"],\n",
    "    \"Accuracy\": [acc_sup, acc_semi],\n",
    "    \"F1\": [f1_sup, f1_semi],\n",
    "    \"Recall\": [rec_sup, rec_semi]\n",
    "})\n",
    "\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apprentissage-semi-supervise-9977Hg6q-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
